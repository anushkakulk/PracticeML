{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear function: autogen grad: \n",
      " [[1.1208656 ]\n",
      " [1.02069091]]\n",
      "linear function: theoret grad: \n",
      " [[1.1208656 ]\n",
      " [1.02069091]] \n",
      "\n",
      "quad function: autogen grad: \n",
      " [[1.59550058]\n",
      " [1.2319578 ]]\n",
      "quad function: theoret grad: \n",
      " [[1.59550058]\n",
      " [1.2319578 ]] \n",
      "\n",
      "trace of quad function: autogen grad: \n",
      " [[1.59550058]\n",
      " [1.2319578 ]]\n",
      "trace of quad function: theoret grad: \n",
      " [[1.59550058]\n",
      " [1.2319578 ]] \n",
      "\n",
      "relu function: autogen grad: \n",
      " [[0.14006323]\n",
      " [0.25695632]]\n",
      "relu function: theoret grad: \n",
      " [[0.14006323]\n",
      " [0.25695632]] \n",
      "\n",
      "linear regression function: autogen grad: \n",
      " [[0.73947777]\n",
      " [0.60500212]]\n",
      "linear regression function: theoret grad: \n",
      " [[0.73947777]\n",
      " [0.60500212]] \n",
      "\n",
      "multivariate gaussian trace function: autogen grad: \n",
      " [[-0.3878101 ]\n",
      " [-0.29915619]]\n",
      "multivariate gaussian trace function: theoret grad: \n",
      " [[-0.3878101 ]\n",
      " [-0.29915619]] \n",
      "\n",
      "multivariate gaussian function: autogen grad: \n",
      " [[-0.3878101 ]\n",
      " [-0.29915619]]\n",
      "multivariate gaussian function: theoret grad: \n",
      " [[-0.3878101 ]\n",
      " [-0.29915619]] \n",
      "\n",
      "sigmoid function: autogen grad: \n",
      " [0.24591833]\n",
      "sigmoid function: theoret grad: \n",
      " [0.24591833] \n",
      "\n",
      "logistic regression objective: autogen grad: \n",
      " [[0.03408508]\n",
      " [0.06253159]]\n",
      "logistic regression objective: theoret grad: \n",
      " [[0.03408508]\n",
      " [0.06253159]] \n",
      "\n",
      "L1 Norm: autogen grad: \n",
      " [[1.]\n",
      " [1.]]\n",
      "L1 Norm: theoret grad: \n",
      " [[1.]\n",
      " [1.]] \n",
      "\n",
      "L2 Norm: autogen grad: \n",
      " [[0.47860256]\n",
      " [0.87803166]]\n",
      "L2 Norm: theoret grad: \n",
      " [[0.47860256]\n",
      " [0.87803166]] \n",
      "\n",
      "pca objective: autogen grad: \n",
      " [[0.30306665]\n",
      " [0.11362567]]\n",
      "pca objective: theoret grad: \n",
      " [[0.30306665]\n",
      " [0.11362567]] \n",
      "\n",
      "gaussian maximum likelihood: autogen grad: \n",
      " -7.19907928944952\n",
      "gaussian maximum likelihood: theoret grad: \n",
      " -7.199079289449519 \n",
      "\n",
      "exponential maximum likelihood: autogen grad: \n",
      " 4.560114359008533\n",
      "exponential maximum likelihood: theoret grad: \n",
      " [4.56011436] \n",
      "\n",
      "bernoulli maximum likelihood: autogen grad: \n",
      " -1.5355998553597168\n",
      "bernoulli maximum likelihood: theoret grad: \n",
      " -1.535599855359717 \n",
      "\n",
      "uniform maximum likelihood: autogen grad: \n",
      " 3.4237429941016035\n",
      "uniform maximum likelihood: theoret grad: \n",
      " 3.4237429941016044 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "from autograd.numpy import log\n",
    "from scipy.integrate import quad\n",
    "import scipy.linalg as linalg\n",
    "import math\n",
    "\n",
    "n = 2\n",
    "A = np.random.random((n,n))\n",
    "w = np.random.random((n,1))\n",
    "y = np.random.random((n,1))\n",
    "x = np.random.random((n,1))\n",
    "\n",
    "# 1) linear \n",
    "def linear(x, y):\n",
    "    return np.dot(np.transpose(y),x) + np.dot(np.transpose(x), (np.array([[1],[1]])))\n",
    "grad_foo1 = grad(linear)\n",
    "print(\"linear function: autogen grad: \\n\", grad_foo1(x, y))\n",
    "print(\"linear function: theoret grad: \\n\", y + (np.array([[1],[1]])), \"\\n\")\n",
    "\n",
    "# 2) quadratic\n",
    "def quad(x, A):\n",
    "    return np.dot(np.dot(np.transpose(x), A), x)\n",
    "grad_foo2 = grad(quad)\n",
    "print(\"quad function: autogen grad: \\n\", grad_foo2(w, A))\n",
    "print(\"quad function: theoret grad: \\n\", np.dot((np.transpose(A) + A), w), \"\\n\")\n",
    "\n",
    "#3) trace of quadratic\n",
    "def trace_quad(x, A):\n",
    "    return np.trace(np.dot(np.dot(np.transpose(x), A), x))\n",
    "grad_foo3 = grad(trace_quad)\n",
    "print(\"trace of quad function: autogen grad: \\n\", grad_foo3(w, A))\n",
    "print(\"trace of quad function: theoret grad: \\n\", np.dot((np.transpose(A) + A), w), \"\\n\")\n",
    "\n",
    "# 4) activation function / ReLU\n",
    "def relu(w, x):\n",
    "    v = np.dot(np.transpose(w), x)\n",
    "    return np.maximum(0, v)\n",
    "def grad_relu(w,x):\n",
    "    if w.T.dot(x) > 0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "grad_foo4 = grad(relu)\n",
    "print(\"relu function: autogen grad: \\n\", grad_foo4(w, x))\n",
    "print(\"relu function: theoret grad: \\n\", grad_relu(w,x), \"\\n\")\n",
    "\n",
    "# 5) linear regression \n",
    "def linreg(w, x, y):\n",
    "    total_sum = 0\n",
    "    for i in range(n):\n",
    "        before_sqr = (np.dot(w.T, x[i]) - y[i])\n",
    "        total_sum += np.dot(before_sqr, before_sqr)\n",
    "    return .5 * total_sum\n",
    "def grad_linreg(w, x, y):\n",
    "    total_sum = 0\n",
    "    for i in range(n):\n",
    "        total_sum += (np.dot(w.T, x[i, :]) - y[i]) * x[i,]\n",
    "    return total_sum\n",
    "grad_foo5 = grad(linreg)\n",
    "print(\"linear regression function: autogen grad: \\n\", grad_foo5(w, A, y))\n",
    "print(\"linear regression function: theoret grad: \\n\", np.reshape(grad_linreg(w, A ,y), (-1, 1)), \"\\n\")\n",
    "\n",
    "# 6) multivariate gaussian trace\n",
    "def trace_mult_gaus(x, A):\n",
    "  return pow(math.e, -np.trace(np.dot(np.dot(np.transpose(x), A), x)))\n",
    "def grad_trace_mult_gaus(x, A):\n",
    "    return -1 * pow(math.e, -(np.dot(np.dot(np.transpose(x), A), x))) * np.dot((np.transpose(A) + A), x)\n",
    "grad_foo6 = grad(trace_mult_gaus)\n",
    "print(\"multivariate gaussian trace function: autogen grad: \\n\", grad_foo6(x,A))\n",
    "print(\"multivariate gaussian trace function: theoret grad: \\n\", grad_trace_mult_gaus(x,A), \"\\n\")\n",
    "\n",
    "# 7) multivariate gaussian\n",
    "def mult_gaus(x, A):\n",
    "  return pow(math.e, -(np.dot(np.dot(np.transpose(x), A), x)))\n",
    "def grad_mult_gaus(x, A):\n",
    "    return -1 * pow(math.e, -(np.dot(np.dot(np.transpose(x), A), x))) * np.dot((np.transpose(A) + A), x)\n",
    "grad_foo7 = grad(mult_gaus)\n",
    "print(\"multivariate gaussian function: autogen grad: \\n\", grad_foo7(x,A))\n",
    "print(\"multivariate gaussian function: theoret grad: \\n\", grad_mult_gaus(x,A), \"\\n\")\n",
    "\n",
    "# 8) sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def grad_sigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "grad_foo8 = grad(sigmoid)\n",
    "print(\"sigmoid function: autogen grad: \\n\", grad_foo8(x[1,:]))\n",
    "print(\"sigmoid function: theoret grad: \\n\", grad_sigmoid(x[1,:]), \"\\n\")\n",
    "\n",
    "# 9) logistic regression objective function\n",
    "def log_reg_obj(w, x):\n",
    "    return 1 / (1 + pow(math.e, (-np.dot(w.T, x))))\n",
    "def grad_log_reg_obj(w, x):\n",
    "    return (x * pow(math.e, (-np.dot(w.T, x)))) / ((1 + pow(math.e, (-np.dot(w.T, x))))**2)\n",
    "grad_foo9 = grad(log_reg_obj)\n",
    "print(\"logistic regression objective: autogen grad: \\n\", grad_foo9(w, x))\n",
    "print(\"logistic regression objective: theoret grad: \\n\", grad_log_reg_obj(w,x), \"\\n\")\n",
    "\n",
    "# 10) L1 norm\n",
    "def l1(x):\n",
    "    return np.sum(np.abs(x))\n",
    "def grad_l1(x):\n",
    "    sign = np.zeros_like(x)\n",
    "    for i in range(n):\n",
    "        if x[i, 0] > 0:\n",
    "            sign[i, 0] = 1\n",
    "        else:\n",
    "            sign[i, 0] = -1\n",
    "    return sign\n",
    "grad_foo10 = grad(l1)\n",
    "print(\"L1 Norm: autogen grad: \\n\", grad_foo10(x))\n",
    "print(\"L1 Norm: theoret grad: \\n\", grad_l1(x), \"\\n\")\n",
    "\n",
    "# 11) L2 norm\n",
    "def l2(x):\n",
    "    sum_squared = 0\n",
    "    for i in range(n):\n",
    "        sum_squared += x[i, 0]**2\n",
    "    return np.sqrt(sum_squared)\n",
    "def grad_l2(x):\n",
    "    return x / l2(x)\n",
    "grad_foo11 = grad(l2)\n",
    "print(\"L2 Norm: autogen grad: \\n\", grad_foo11(x))\n",
    "print(\"L2 Norm: theoret grad: \\n\", grad_l2(x), \"\\n\")\n",
    "\n",
    "# 12) SVM objective : SKIP\n",
    "\n",
    "# 13) PCA objective\n",
    "lam = np.random.random()\n",
    "def pca(x, A):\n",
    "    return np.dot(np.dot(np.transpose(x), A), x) - lam * (np.dot(np.dot(np.transpose(x), np.identity(n)), x) - 1)\n",
    "grad_foo13 = grad(pca)\n",
    "print(\"pca objective: autogen grad: \\n\", grad_foo13(x, A))\n",
    "print(\"pca objective: theoret grad: \\n\", np.dot((np.transpose(A) + A), x) - 2 * lam * x, \"\\n\")\n",
    "\n",
    "# 14) gaussian maximum likelihood\n",
    "mu = np.random.random()\n",
    "sig = np.random.random()\n",
    "def gauss_max(mu, sig, x):\n",
    "    n = len(x)\n",
    "    prod = 1\n",
    "    for i in range(n):\n",
    "        prod *= (1 / (sig * np.sqrt(2 * np.pi))) * (np.exp(-np.linalg.norm(x[i] - mu)**2 / (2 * sig**2)))\n",
    "    return np.log(prod)\n",
    "def grad_gauss_max(mu, sig, x):\n",
    "    n = len(x)\n",
    "    sum = 0\n",
    "    for i in range(n):\n",
    "        sum += (x[i] - mu) \n",
    "    return sum / sig**2\n",
    "grad_foo14 = grad(gauss_max)\n",
    "print(\"gaussian maximum likelihood: autogen grad: \\n\", grad_foo14(mu, sig, x))\n",
    "print(\"gaussian maximum likelihood: theoret grad: \\n\", np.sum(grad_gauss_max(mu, sig, x)), \"\\n\")\n",
    "\n",
    "# 15) exponential maximum likelihood\n",
    "def exp_max(lam, x):\n",
    "    n = len(x)\n",
    "    prod = 1\n",
    "    for i in range(n):\n",
    "         prod *= lam * np.exp(-lam * x[i, :])\n",
    "    return np.log(prod)\n",
    "def grad_exp_max(lam, x):\n",
    "    n = len(x)\n",
    "    sum = 0\n",
    "    for i in range(n):\n",
    "        sum += (1/lam) - x[i, :]\n",
    "    return sum\n",
    "grad_foo15 = grad(exp_max)\n",
    "print(\"exponential maximum likelihood: autogen grad: \\n\", grad_foo15(lam, x))\n",
    "print(\"exponential maximum likelihood: theoret grad: \\n\", grad_exp_max(lam,x), \"\\n\")\n",
    "\n",
    "# 16) bernoulli maximum likelihood\n",
    "p = np.random.random()\n",
    "a = np.random.uniform(0,1)\n",
    "def bern_max(p, a):\n",
    "    prod = 1\n",
    "    for i in range(n):\n",
    "        prod *= pow(p, a) * pow(1 - p, 1 - a)\n",
    "    return np.log(prod)\n",
    "def grad_bern_max(p, a):\n",
    "    sum = 0\n",
    "    for i in range(n):\n",
    "        sum += (a/p) - ((1 - a) / (1 - p))\n",
    "    return sum\n",
    "grad_foo16 = grad(bern_max)\n",
    "print(\"bernoulli maximum likelihood: autogen grad: \\n\", grad_foo16(p, a))\n",
    "print(\"bernoulli maximum likelihood: theoret grad: \\n\", grad_bern_max(p, a), \"\\n\")\n",
    "\n",
    "# 17) uniform maximum likelihood\n",
    "a = np.random.uniform(0, 1)\n",
    "b = np.random.uniform(a, 1)\n",
    "def unif_max(a,b):\n",
    "    prod = 1\n",
    "    for i in range(n):\n",
    "         prod *= 1 / (b - a)\n",
    "    return np.log(prod)\n",
    "def grad_unif_max(a, b):\n",
    "    return n / (b - a)\n",
    "grad_foo17 = grad(unif_max)\n",
    "print(\"uniform maximum likelihood: autogen grad: \\n\", grad_foo17(a, b))\n",
    "print(\"uniform maximum likelihood: theoret grad: \\n\", grad_unif_max(a,b), \"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
