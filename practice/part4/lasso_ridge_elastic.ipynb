{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Train MSE: 2.122974823830284\n",
      "Lasso Regression Validation MSE: 2.36652082021916\n",
      "SKLearn Lasso Train MSE: 6.831045121140056\n",
      "SKLearn Lasso Validation MSE: 7.629002980184825\n",
      "My Lasso Regression Validation MSE: 0.09295127686258224 for lambda: 0\n",
      "My Lasso Regression Validation MSE: 0.09554581350427192 for lambda: 0.1\n",
      "My Lasso Regression Validation MSE: 2.36652082021916 for lambda: 1\n",
      "My Lasso Regression Validation MSE: 46.705761270943 for lambda: 10\n",
      "Best lambda: 0 with MSE: 0.09295127686258224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso as SKLasso, Ridge as SKRidge, ElasticNet as SKEnet\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from enum import Enum\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "X = np.genfromtxt('easier_data.csv', delimiter=',')\n",
    "y = np.genfromtxt('label.csv', delimiter=',')\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_rest, y_rest, test_size=0.5, random_state=42)\n",
    "\n",
    "# use standard scaler to normalize the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = PolynomialFeatures(degree=2, include_bias=True).fit_transform(X_train)\n",
    "X_val = PolynomialFeatures(degree=2, include_bias=True).fit_transform(X_val)\n",
    "X_test = PolynomialFeatures(degree=2, include_bias=True).fit_transform(X_test)\n",
    "\n",
    "def ߜLasso(w: ndarray, Φ: ndarray, y: ndarray, λ: float) -> ndarray:\n",
    "    \"\"\"\n",
    "    calcs the gradient of the Lasso loss function with respect to weights (w).\n",
    "    \"\"\"\n",
    "    n, m = Φ.shape\n",
    "    return 2/n * Φ.T.dot(Φ.dot(w) - y) + λ * np.sign(w) # if λ = 0, this is the gradient of the MSE loss function\n",
    "\n",
    "def grad_lasso(Φ: ndarray, y: ndarray, α: float = 0.01, num_iter: int = 10_000, λ: float = 1) -> ndarray:\n",
    "    \"\"\"\n",
    "    Performs gradient descent on Lasso Rregression Objective to find optimal w vector.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - Φ: ndarray, The feature matrix (Phi).\n",
    "    - y: ndarray, The target values.\n",
    "    - α: float, The learning rate.\n",
    "    - num_iter: int, The number of training iterations.\n",
    "    - λ: float, The regularization parameter.\n",
    "\n",
    "    Returns:\n",
    "    - ndarray: The optimized weights vector.\n",
    "    \"\"\"\n",
    "    n, m = Φ.shape\n",
    "    w = np.zeros((m, 1))\n",
    "    for _ in range(num_iter):\n",
    "        gradient = ߜLasso(w, Φ, y, λ=λ)  # gradient of lasso with respect to w\n",
    "        \n",
    "        #  convergence \n",
    "        if np.all(np.abs(gradient) < 1e-5) or np.isnan(gradient).any():\n",
    "            break\n",
    "            \n",
    "       \n",
    "        if np.isinf(gradient).any(): \n",
    "            raise ValueError(\"Gradient exploded\")\n",
    "\n",
    "        w -= α * gradient\n",
    "    return w\n",
    "\n",
    "def predict(Φ: ndarray, w: ndarray) -> ndarray:\n",
    "    \"\"\"\n",
    "    Predicts the target values using the linear model.\n",
    "    \"\"\"\n",
    "    return Φ.dot(w)\n",
    "\n",
    "def mse(y: ndarray, y_hat: ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates (MSE) between actual and predicted values.\n",
    "    \"\"\"\n",
    "    return np.mean((y - y_hat)**2)\n",
    "\n",
    "\n",
    "## MY GRAD DESCENT LASSO\n",
    "w_lasso_gd = grad_lasso(X_train, y_train, λ=1)\n",
    "pred_train = predict(X_train, w_lasso_gd)\n",
    "print(f\"Lasso Regression Train MSE: {mse(y_train, pred_train)}\")\n",
    "pred_val = predict(X_val, w_lasso_gd)\n",
    "print(f\"Lasso Regression Validation MSE: {mse(y_val, pred_val)}\")\n",
    "\n",
    "\n",
    "## SKLEARN'S LASSO\n",
    "sk_poly_lasso = SKLasso(alpha=1)\n",
    "sk_poly_lasso.fit(X_train,y_train.flatten()) # y is 2D, but scikit-learn expects 1D\n",
    "pred_train = sk_poly_lasso.predict(X_train).reshape(-1,1)\n",
    "print(f\"SKLearn Lasso Train MSE: {mse(y_train, pred_train)}\")\n",
    "pred_val = sk_poly_lasso.predict(X_val).reshape(-1,1)\n",
    "print(f\"SKLearn Lasso Validation MSE: {mse(y_val, pred_val)}\")\n",
    "\n",
    "## USE VALIDATION - PICK BEST LAMBDA FOR LASSO\n",
    "valid_lambdas = [0, 0.1, 1, 10] # possible lambda\n",
    "best_lambda_lasso = None \n",
    "best_mse_lasso = float('inf') \n",
    "for λ in valid_lambdas:\n",
    "    w_lasso_gd = grad_lasso(X_train, y_train, λ=λ) # train\n",
    "    pred_val = predict(X_val, w_lasso_gd) # predict \n",
    "    mse_ = mse(y_val, pred_val)\n",
    "    print(f\"My Lasso Regression Validation MSE: {mse_} for lambda: {λ}\")\n",
    "    if mse_ < best_mse_lasso:\n",
    "        best_mse_lasso = mse_\n",
    "        best_lambda_lasso = λ\n",
    "print(f\"Best lambda: {best_lambda_lasso} with MSE: {best_mse_lasso}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Ridge Regression Train MSE: 12.639576707863059\n",
      "My Ridge Regression Validation MSE: 16.015452828238868\n",
      "SKLearn Ridge Train MSE: 0.03284528040883187\n",
      "SKLearn Ridge Validation MSE: 0.10389999417330299\n",
      "My Ridge Regression Validation MSE: 0.09295127686258224 for lambda: 0\n",
      "My Ridge Regression Validation MSE: 1.1402329224528367 for lambda: 0.1\n",
      "My Ridge Regression Validation MSE: 16.015452828238868 for lambda: 1\n",
      "My Ridge Regression Validation MSE: 42.66613532773383 for lambda: 10\n",
      "Best lambda: 0 with MSE: 0.09295127686258224\n"
     ]
    }
   ],
   "source": [
    "def ߜRidge(w: ndarray, Φ: ndarray, y: ndarray, λ: float) -> ndarray:\n",
    "    \"\"\"\n",
    "    Calc Gradient of the Ridge loss  with respect to weights (w).\n",
    "    \"\"\"\n",
    "    n, m = Φ.shape\n",
    "    return 2/n * Φ.T.dot(Φ.dot(w) - y) + 2 * λ * w # if λ = 0, this is the gradient of the MSE loss function\n",
    "\n",
    "def gradient_descent_ridge(Φ: ndarray, y: ndarray, α: float = 0.01, num_iter: int = 10_000, λ: float = 1) -> ndarray:\n",
    "    \"\"\"\n",
    "    gradient descent on Ridge Rregression Objective to find best w vector.\n",
    "    \"\"\"\n",
    "    n, m = Φ.shape\n",
    "    w = np.zeros((m, 1))\n",
    "    for _ in range(num_iter):\n",
    "        gradient = ߜRidge(w, Φ, y, λ=λ)  # Grad Ridge  with respect to w \n",
    "        \n",
    "        # convergence \n",
    "        if np.all(np.abs(gradient) < 1e-5) or np.isnan(gradient).any():\n",
    "            break\n",
    "            \n",
    "        \n",
    "        if np.isinf(gradient).any(): \n",
    "            raise ValueError(\"Gradient exploded\")\n",
    "\n",
    "        w -= α * gradient\n",
    "    return w\n",
    "\n",
    "## MY GRAD DESCENT RIDGE\n",
    "w_ridge_gd = gradient_descent_ridge(X_train, y_train, λ=1)\n",
    "pred_train = predict(X_train, w_ridge_gd)\n",
    "print(f\"My Ridge Regression Train MSE: {mse(y_train, pred_train)}\")\n",
    "pred_val = predict(X_val, w_ridge_gd)\n",
    "print(f\"My Ridge Regression Validation MSE: {mse(y_val, pred_val)}\")\n",
    "\n",
    "## SKLEARNS RIDGE REGRESSION \n",
    "sk_poly_ridge = SKRidge(alpha=1)\n",
    "sk_poly_ridge.fit(X_train,y_train.flatten()) # y is 2D, but scikit-learn expects 1D\n",
    "pred_train = sk_poly_ridge.predict(X_train).reshape(-1,1)\n",
    "print(f\"SKLearn Ridge Train MSE: {mse(y_train, pred_train)}\")\n",
    "pred_val = sk_poly_ridge.predict(X_val).reshape(-1,1)\n",
    "print(f\"SKLearn Ridge Validation MSE: {mse(y_val, pred_val)}\")\n",
    "\n",
    "## PICK BEST LAMBDAS \n",
    "valid_lambdas = [0, 0.1, 1, 10] # possible values for lambda \n",
    "best_lambda_ridge = None # best lambda value\n",
    "best_mse_ridge = float('inf') # best mse value\n",
    "for λ in valid_lambdas:\n",
    "    w_ridge_gd = gradient_descent_ridge(X_train, y_train, λ=λ) \n",
    "    pred_val = predict(X_val, w_ridge_gd) # predict \n",
    "    mse_ = mse(y_val, pred_val)\n",
    "    print(f\"My Ridge Regression Validation MSE: {mse_} for lambda: {λ}\")\n",
    "    if mse_ < best_mse_ridge:\n",
    "        best_mse_ridge = mse_\n",
    "        best_lambda_ridge = λ\n",
    "print(f\"Best lambda: {best_lambda_ridge} with MSE: {best_mse_ridge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Elastic Net Regression Train MSE: 12.683717066642759\n",
      "My Elastic Net Regression Validation MSE: 15.999226190919423\n",
      "SKLearn Elastic Net Train MSE: 10.59413111704921\n",
      "SKLearn Elastic Net Validation MSE: 10.827746499666107\n",
      "Elastic Net Validation MSE: 0.8537073116711 for alpha: 0.1 and l1_ratio: 0.1\n",
      "Elastic Net Validation MSE: 0.30885498900871583 for alpha: 0.1 and l1_ratio: 0.5\n",
      "Elastic Net Validation MSE: 0.17011228553396876 for alpha: 0.1 and l1_ratio: 0.9\n",
      "Elastic Net Validation MSE: 7.216370675118712 for alpha: 0.5 and l1_ratio: 0.1\n",
      "Elastic Net Validation MSE: 3.9952725054312244 for alpha: 0.5 and l1_ratio: 0.5\n",
      "Elastic Net Validation MSE: 2.40985903418246 for alpha: 0.5 and l1_ratio: 0.9\n",
      "Elastic Net Validation MSE: 14.472627966055745 for alpha: 1 and l1_ratio: 0.1\n",
      "Elastic Net Validation MSE: 10.827746499666107 for alpha: 1 and l1_ratio: 0.5\n",
      "Elastic Net Validation MSE: 8.447437223690004 for alpha: 1 and l1_ratio: 0.9\n",
      "Best alpha: None, Best l1_ratio: None with MSE: 0.17011228553396876\n"
     ]
    }
   ],
   "source": [
    "def elastic_net(w: ndarray, Φ: ndarray, y: ndarray, λ: float, α: float) -> ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Gradient of the Elastic Net loss with respect to weights (w).\n",
    "    \"\"\"\n",
    "    n, m = Φ.shape\n",
    "    ridge_grad = 2/n * Φ.T.dot(Φ.dot(w) - y) + 2 * λ * w\n",
    "    lasso_grad = λ * np.sign(w)\n",
    "    return ridge_grad + α * lasso_grad\n",
    "\n",
    "def gradient_descent_elastic_net(Φ: ndarray, y: ndarray, α: float = 0.01, num_iter: int = 10_000, λ: float = 1, l1_ratio: float = 0.5) -> ndarray:\n",
    "    \"\"\"\n",
    "    Gradient descent on Elastic Net Regression Objective to find the best w vector.\n",
    "    \"\"\"\n",
    "    n, m = Φ.shape\n",
    "    w = np.zeros((m, 1))\n",
    "    for _ in range(num_iter):\n",
    "        gradient = elastic_net(w, Φ, y, λ, α)  # Gradient of Elastic Net with respect to w\n",
    "        \n",
    "        # Convergence\n",
    "        if np.all(np.abs(gradient) < 1e-5) or np.isnan(gradient).any():\n",
    "            break\n",
    "            \n",
    "        if np.isinf(gradient).any(): \n",
    "            raise ValueError(\"Gradient exploded\")\n",
    "\n",
    "        w -= α * gradient\n",
    "    return w\n",
    "\n",
    "# GRAD DESC ELASTIC NET\n",
    "w_elastic_net_gd = gradient_descent_elastic_net(X_train, y_train, α=0.01, λ=1, l1_ratio=0.5)\n",
    "pred_train = predict(X_train, w_elastic_net_gd)\n",
    "print(f\"My Elastic Net Regression Train MSE: {mse(y_train, pred_train)}\")\n",
    "pred_val = predict(X_val, w_elastic_net_gd)\n",
    "print(f\"My Elastic Net Regression Validation MSE: {mse(y_val, pred_val)}\")\n",
    "\n",
    "# Create an instance of the ElasticNet model\n",
    "sk_elastic_net = SKEnet(alpha=1, l1_ratio=0.5)  # Set alpha (λ) and l1_ratio\n",
    "\n",
    "sk_elastic_net.fit(X_train, y_train.flatten())  # y_train should be 1D\n",
    "\n",
    "pred_train = sk_elastic_net.predict(X_train).reshape(-1, 1)\n",
    "print(f\"SKLearn Elastic Net Train MSE: {mse(y_train, pred_train)}\")\n",
    "pred_val = sk_elastic_net.predict(X_val).reshape(-1, 1)\n",
    "print(f\"SKLearn Elastic Net Validation MSE: {mse(y_val, pred_val)}\")\n",
    "\n",
    "## PICK BEST LAMBDA/ALPHA\n",
    "valid_alphas = [0.1, 0.5, 1]  # possible values for alpha (λ)\n",
    "valid_l1_ratios = [0.1, 0.5, 0.9]  # possible values for l1_ratio\n",
    "\n",
    "best_alpha_elastic_net = None\n",
    "best_l1_ratio_elastic_net = None\n",
    "best_mse_elastic_net = float('inf')\n",
    "\n",
    "for alpha in valid_alphas:\n",
    "    for l1_ratio in valid_l1_ratios:\n",
    "        sk_elastic_net = SKEnet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "        sk_elastic_net.fit(X_train, y_train.flatten()) \n",
    "        pred_val = sk_elastic_net.predict(X_val).reshape(-1, 1) \n",
    "        mse_val = mse(y_val, pred_val)\n",
    "        print(f\"Elastic Net Validation MSE: {mse_val} for alpha: {alpha} and l1_ratio: {l1_ratio}\")\n",
    "        \n",
    "        if mse_val < best_mse_elastic_net:\n",
    "            best_mse_elastic_net = mse_val\n",
    "            best_alpha = alpha\n",
    "            best_l1_ratio = l1_ratio\n",
    "\n",
    "print(f\"Best alpha: {best_alpha_elastic_net}, Best l1_ratio: {best_l1_ratio_elastic_net} with MSE: {best_mse_elastic_net}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Rankings based on MSE:\n",
      "1. Lasso: 0.09295127686258224\n",
      "2. Ridge: 0.09295127686258224\n",
      "3. Elastic Net: 0.17011228553396876\n",
      "\n",
      "Best Model: Lasso with MSE: 0.09295127686258224\n"
     ]
    }
   ],
   "source": [
    "mse_dict = {\"Elastic Net\": best_mse_elastic_net, \"Lasso\": best_mse_lasso, \"Ridge\": best_mse_ridge}\n",
    "\n",
    "sorted_models = sorted(mse_dict.items(), key=lambda x: x[1])\n",
    "\n",
    "print(\"Model Rankings based on MSE:\")\n",
    "for rank, (model, mse) in enumerate(sorted_models, start=1):\n",
    "    print(f\"{rank}. {model}: {mse}\")\n",
    "\n",
    "best_model, best_mse = sorted_models[0]\n",
    "\n",
    "print(f\"\\nBest Model: {best_model} with MSE: {best_mse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
